{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2118595,"sourceType":"datasetVersion","datasetId":1271215}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.486763Z","iopub.execute_input":"2025-07-16T11:25:21.487397Z","iopub.status.idle":"2025-07-16T11:25:21.617247Z","shell.execute_reply.started":"2025-07-16T11:25:21.487367Z","shell.execute_reply":"2025-07-16T11:25:21.615996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport shutil\nimport random\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional, Set\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict, Counter\nimport warnings\nimport xml.etree.ElementTree as ET\n\n# Import required libraries\ntry:\n    from PIL import Image\n    from tqdm import tqdm\nexcept ImportError as e:\n    print(f\"Missing required library: {e}\")\n    print(\"Please install with: pip install tqdm pillow\")\n    exit(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.619037Z","iopub.execute_input":"2025-07-16T11:25:21.619448Z","iopub.status.idle":"2025-07-16T11:25:21.636580Z","shell.execute_reply.started":"2025-07-16T11:25:21.619398Z","shell.execute_reply":"2025-07-16T11:25:21.635406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@dataclass\nclass DatasetConfig:\n    \"\"\"Configuration for Pascal VOC dataset processing\"\"\"\n    \n    # Basic settings\n    random_seed: int = 42\n    dataset_name: str = \"pascal_voc_test_dataset\"\n    \n    # Pascal VOC dataset path\n    voc_path: str = '/kaggle/input/pascal-voc-2012-dataset'\n    \n    # Output path\n    output_path: str = '/kaggle/working'\n    \n    # Class mapping - VOC classes to target classes\n    class_mapping: Dict[str, str] = field(default_factory=lambda: {\n        'person': 'person',\n        'cat': 'pet',\n        'dog': 'pet',\n        'bus': 'car',\n        'truck': 'car',\n        'car': 'car'\n    })\n    \n    # A fixed order of categories is critical!\n    target_classes: List[str] = field(default_factory=lambda: [\n        'person',\n        'pet', \n        'car'\n    ])\n    \n    # Dataset sizes for each target class\n    dataset_sizes: Dict[str, int] = field(default_factory=lambda: {\n        'person': 2000,\n        'pet': 2000,\n        'car': 2000,\n        'negative': 1000\n    })\n    \n    def __post_init__(self):\n        self.full_output_path = os.path.join(self.output_path, self.dataset_name)\n        self.voc_classes = list(self.class_mapping.keys())\n        \n        # Validation: check that all class_mapping values are in target_classes\n        mapped_classes = set(self.class_mapping.values())\n        target_classes_set = set(self.target_classes)\n        \n        if not mapped_classes.issubset(target_classes_set):\n            missing = mapped_classes - target_classes_set\n            raise ValueError(f\"Class mapping contains classes that are not in target_classes: {missing}\")\n        \n        print(f\"VOC Dataset config initialized: {self.dataset_name}\")\n        print(f\"VOC classes: {self.voc_classes}\")\n        print(f\"Target classes (ordered): {self.target_classes}\")\n        print(f\"Output path: {self.full_output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.638802Z","iopub.execute_input":"2025-07-16T11:25:21.639148Z","iopub.status.idle":"2025-07-16T11:25:21.653299Z","shell.execute_reply.started":"2025-07-16T11:25:21.639120Z","shell.execute_reply":"2025-07-16T11:25:21.652210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class VOCProcessor:\n    \"\"\"Main class for processing Pascal VOC dataset\"\"\"\n    \n    def __init__(self, config: DatasetConfig):\n        self.config = config\n        self.voc_data = {}\n        self.class_stats = {}\n        self.coco_categories = []\n        self.category_id_mapping = {}\n        \n        # Setup random seed\n        random.seed(config.random_seed)\n        print(f\"Random seed set to: {config.random_seed}\")\n        \n        # Create COCO category mapping\n        self._create_coco_categories()\n    \n    def _create_coco_categories(self):\n        \"\"\"Create COCO format categories from target classes\"\"\"\n        category_id = 1\n        \n        # IMPORTANT: use the fixed order from config.target_classes\n        for target_class in self.config.target_classes:\n            self.coco_categories.append({\n                'id': category_id,\n                'name': target_class,\n                'supercategory': target_class  \n            })\n            self.category_id_mapping[target_class] = category_id\n            category_id += 1\n        \n        print(f\"Created {len(self.coco_categories)} COCO categories in fixed order:\")\n        for cat in self.coco_categories:\n            print(f\"  ID {cat['id']}: {cat['name']} (supercategory: {cat['supercategory']})\")\n    \n    def setup_directories(self):\n        \"\"\"Create necessary output directories\"\"\"\n        print(\"Setting up output directories...\")\n        \n        # Create main output directory\n        Path(self.config.full_output_path).mkdir(exist_ok=True, parents=True)\n        \n        # Create test directory\n        Path(self.config.full_output_path, 'test').mkdir(exist_ok=True)\n        \n        # Create annotations directory\n        Path(self.config.full_output_path, 'annotations').mkdir(exist_ok=True)\n        \n        print(\"Directories created successfully\")\n    \n    def load_voc_data(self):\n        \"\"\"Load Pascal VOC dataset from both test and train_val sets\"\"\"\n        print(\"Loading Pascal VOC dataset...\")\n        \n        try:\n            # Define both test and train_val paths\n            voc_paths = [\n                os.path.join(self.config.voc_path, 'VOC2012_test', 'VOC2012_test'),\n                os.path.join(self.config.voc_path, 'VOC2012_train_val', 'VOC2012_train_val')\n            ]\n            \n            total_processed = 0\n            \n            for voc_root in voc_paths:\n                if not os.path.exists(voc_root):\n                    print(f\"Path not found: {voc_root}\")\n                    continue\n                    \n                print(f\"Processing: {voc_root}\")\n                \n                # Load annotations\n                annotations_path = os.path.join(voc_root, 'Annotations')\n                images_path = os.path.join(voc_root, 'JPEGImages')\n                \n                if not os.path.exists(annotations_path):\n                    print(f\"Annotations directory not found: {annotations_path}\")\n                    continue\n                \n                if not os.path.exists(images_path):\n                    print(f\"Images directory not found: {images_path}\")\n                    continue\n                \n                # Process all annotation files in this directory\n                annotation_files = [f for f in os.listdir(annotations_path) if f.endswith('.xml')]\n                print(f\"Found {len(annotation_files)} annotation files in {os.path.basename(voc_root)}\")\n                \n                for ann_file in tqdm(annotation_files, desc=f\"Loading {os.path.basename(voc_root)} annotations\"):\n                    ann_path = os.path.join(annotations_path, ann_file)\n                    image_id = ann_file.replace('.xml', '')\n                    \n                    # Skip if we already processed this image (avoid duplicates)\n                    if image_id in self.voc_data:\n                        continue\n                    \n                    # Parse XML annotation\n                    tree = ET.parse(ann_path)\n                    root = tree.getroot()\n                    \n                    # Get image info\n                    filename = root.find('filename').text\n                    size = root.find('size')\n                    width = int(size.find('width').text)\n                    height = int(size.find('height').text)\n                    \n                    # Check if image file exists\n                    img_path = os.path.join(images_path, filename)\n                    if not os.path.exists(img_path):\n                        continue\n                    \n                    # Parse objects\n                    objects = []\n                    for obj in root.findall('object'):\n                        voc_class = obj.find('name').text\n                        \n                        # Only include classes we want to map\n                        if voc_class in self.config.class_mapping:\n                            target_class = self.config.class_mapping[voc_class]\n                            \n                            bbox = obj.find('bndbox')\n                            xmin = int(float(bbox.find('xmin').text))\n                            ymin = int(float(bbox.find('ymin').text))\n                            xmax = int(float(bbox.find('xmax').text))\n                            ymax = int(float(bbox.find('ymax').text))\n                            \n                            objects.append({\n                                'voc_class': voc_class,\n                                'target_class': target_class,\n                                'bbox': [xmin, ymin, xmax, ymax]\n                            })\n                    \n                    # Store image data\n                    self.voc_data[image_id] = {\n                        'filename': filename,\n                        'width': width,\n                        'height': height,\n                        'objects': objects,\n                        'image_path': img_path\n                    }\n                    total_processed += 1\n            \n            print(f\"Loaded {len(self.voc_data)} unique images with annotations\")\n            print(f\"Total files processed: {total_processed}\")\n            \n            if len(self.voc_data) == 0:\n                print(\"No valid VOC data found!\")\n                raise FileNotFoundError(\"No valid VOC data found\")\n            \n        except Exception as e:\n            print(f\"Error loading VOC data: {e}\")\n            raise\n    \n    \n    def analyze_class_distribution(self):\n        \"\"\"Analyze distribution of target classes\"\"\"\n        print(\"Analyzing class distribution...\")\n        \n        try:\n            class_counts = {}\n            class_images = {}\n            \n            # Initialize counters –í–ò–ö–û–†–ò–°–¢–û–í–£–Æ–ß–ò –§–Ü–ö–°–û–í–ê–ù–ò–ô –ü–û–†–Ø–î–û–ö\n            for target_class in self.config.target_classes:\n                class_counts[target_class] = 0\n                class_images[target_class] = set()\n            \n            # Count images and annotations for each target class\n            for image_id, data in self.voc_data.items():\n                image_classes = set()\n                for obj in data['objects']:\n                    target_class = obj['target_class']\n                    class_counts[target_class] += 1\n                    image_classes.add(target_class)\n                \n                # Add image to each class it contains\n                for target_class in image_classes:\n                    class_images[target_class].add(image_id)\n            \n            # Count negative images (images without any target classes)\n            all_target_images = set()\n            for class_imgs in class_images.values():\n                all_target_images.update(class_imgs)\n            \n            negative_images = set()\n            for image_id in self.voc_data.keys():\n                if image_id not in all_target_images:\n                    negative_images.add(image_id)\n            \n            # Store statistics\n            self.class_stats = {\n                'class_counts': class_counts,\n                'class_images': class_images,\n                'negative_images': negative_images\n            }\n            \n            # Log statistics –í –§–Ü–ö–°–û–í–ê–ù–û–ú–£ –ü–û–†–Ø–î–ö–£\n            print(\"=== CLASS DISTRIBUTION ANALYSIS ===\")\n            for target_class in self.config.target_classes:\n                img_count = len(class_images[target_class])\n                ann_count = class_counts[target_class]\n                print(f\"{target_class}: {img_count:,} images, {ann_count:,} annotations\")\n            \n            print(f\"negative: {len(negative_images):,} images\")\n            print(f\"Total images: {len(self.voc_data):,}\")\n            \n        except Exception as e:\n            print(f\"Error analyzing class distribution: {e}\")\n            raise\n\n    \n    def sample_images_by_class(self, target_counts: Dict[str, int]) -> Dict[str, List[str]]:\n        \"\"\"Sample images from each class according to target counts\"\"\"\n        print(f\"Sampling images with target counts: {target_counts}\")\n        \n        try:\n            sampled_images = {}\n            \n            # Sample from each target class –í –§–Ü–ö–°–û–í–ê–ù–û–ú–£ –ü–û–†–Ø–î–ö–£\n            for target_class in self.config.target_classes:\n                if target_class in target_counts:\n                    available_ids = list(self.class_stats['class_images'][target_class])\n                    sample_count = min(target_counts[target_class], len(available_ids))\n                    \n                    if sample_count > 0:\n                        sampled = random.sample(available_ids, sample_count)\n                        sampled_images[target_class] = sampled\n                        print(f\"  {target_class}: {sample_count:,} / {len(available_ids):,} images\")\n            \n            # Handle negative images\n            if 'negative' in target_counts:\n                available_ids = list(self.class_stats['negative_images'])\n                sample_count = min(target_counts['negative'], len(available_ids))\n                \n                if sample_count > 0:\n                    sampled = random.sample(available_ids, sample_count)\n                    sampled_images['negative'] = sampled\n                    print(f\"  negative: {sample_count:,} / {len(available_ids):,} images\")\n            \n            return sampled_images\n            \n        except Exception as e:\n            print(f\"Error sampling images: {e}\")\n            raise\n\n    \n    def create_test_dataset(self, sampled_images: Dict[str, List[str]]) -> Tuple[int, int]:\n        \"\"\"Create test dataset with sampled images in COCO format\"\"\"\n        print(\"Creating test dataset...\")\n        \n        try:\n            # Collect all sampled image IDs\n            all_img_ids = []\n            for class_name, img_ids in sampled_images.items():\n                all_img_ids.extend(img_ids)\n            \n            unique_img_ids = list(set(all_img_ids))\n            print(f\"Processing {len(unique_img_ids)} unique images for test\")\n            \n            # Create COCO format data\n            coco_images = []\n            coco_annotations = []\n            annotation_id = 1\n            \n            negative_imgs = set(sampled_images.get('negative', []))\n            \n            for image_id in tqdm(unique_img_ids, desc=\"Processing test images\"):\n                voc_data = self.voc_data[image_id]\n                \n                # Create COCO image entry\n                coco_image = {\n                    'id': int(image_id) if image_id.isdigit() else hash(image_id) % (2**31),\n                    'file_name': voc_data['filename'],\n                    'width': voc_data['width'],\n                    'height': voc_data['height']\n                }\n                coco_images.append(coco_image)\n                \n                # Create COCO annotations (skip negative images)\n                if image_id not in negative_imgs:\n                    for obj in voc_data['objects']:\n                        # Convert VOC bbox to COCO format\n                        xmin, ymin, xmax, ymax = obj['bbox']\n                        width = xmax - xmin\n                        height = ymax - ymin\n                        area = width * height\n                        \n                        coco_annotation = {\n                            'id': annotation_id,\n                            'image_id': coco_image['id'],\n                            'category_id': self.category_id_mapping[obj['target_class']],\n                            'bbox': [xmin, ymin, width, height],\n                            'area': area,\n                            'iscrowd': 0\n                        }\n                        coco_annotations.append(coco_annotation)\n                        annotation_id += 1\n            \n            # Copy image files\n            print(f\"Copying {len(coco_images)} images to test directory...\")\n            \n            for img_data in tqdm(coco_images, desc=\"Copying test images\"):\n                image_id = None\n                for vid, vdata in self.voc_data.items():\n                    if vdata['filename'] == img_data['file_name']:\n                        image_id = vid\n                        break\n                \n                if image_id and image_id in self.voc_data:\n                    src_path = self.voc_data[image_id]['image_path']\n                    dst_path = os.path.join(self.config.full_output_path, 'test', img_data['file_name'])\n                    \n                    if os.path.exists(src_path):\n                        shutil.copy2(src_path, dst_path)\n                    else:\n                        print(f\"Image not found: {src_path}\")\n            \n            # Save annotation file\n            annotation_data = {\n                'images': coco_images,\n                'annotations': coco_annotations,\n                'categories': self.coco_categories\n            }\n            \n            ann_file = os.path.join(self.config.full_output_path, 'annotations', 'instances_test.json')\n            with open(ann_file, 'w') as f:\n                json.dump(annotation_data, f, indent=2)\n            \n            print(f\"‚úÖ Test dataset created: {len(coco_images):,} images, {len(coco_annotations):,} annotations\")\n            return len(coco_images), len(coco_annotations)\n            \n        except Exception as e:\n            print(f\"Error creating test dataset: {e}\")\n            raise\n    \n    def process_dataset(self):\n        \"\"\"Main processing pipeline\"\"\"\n        print(\"Starting Pascal VOC dataset processing pipeline...\")\n        \n        try:\n            # Step 1: Setup\n            self.setup_directories()\n            \n            # Step 2: Load VOC data\n            self.load_voc_data()\n            \n            # Step 3: Analyze class distribution\n            self.analyze_class_distribution()\n            \n            # Step 4: Sample images for test set\n            print(f\"\\n{'='*50}\")\n            print(\"Processing TEST split\")\n            print(f\"{'='*50}\")\n            \n            sampled_images = self.sample_images_by_class(self.config.dataset_sizes)\n            \n            # Step 5: Create test dataset\n            img_count, ann_count = self.create_test_dataset(sampled_images)\n            \n            # Final summary\n            print(f\"\\n{'='*50}\")\n            print(\"FINAL DATASET SUMMARY\")\n            print(f\"{'='*50}\")\n            \n            print(f\"Test: {img_count:,} images, {ann_count:,} annotations\")\n            print(f\"‚úÖ Dataset created successfully at: {self.config.full_output_path}\")\n            \n            return {'test': {'images': img_count, 'annotations': ann_count}}\n            \n        except Exception as e:\n            print(f\"Error in processing pipeline: {e}\")\n            raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.654548Z","iopub.execute_input":"2025-07-16T11:25:21.654930Z","iopub.status.idle":"2025-07-16T11:25:21.713114Z","shell.execute_reply.started":"2025-07-16T11:25:21.654901Z","shell.execute_reply":"2025-07-16T11:25:21.712123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = DatasetConfig()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.714280Z","iopub.execute_input":"2025-07-16T11:25:21.714601Z","iopub.status.idle":"2025-07-16T11:25:21.729940Z","shell.execute_reply.started":"2025-07-16T11:25:21.714574Z","shell.execute_reply":"2025-07-16T11:25:21.728635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processor = VOCProcessor(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.731024Z","iopub.execute_input":"2025-07-16T11:25:21.731375Z","iopub.status.idle":"2025-07-16T11:25:21.750852Z","shell.execute_reply.started":"2025-07-16T11:25:21.731326Z","shell.execute_reply":"2025-07-16T11:25:21.749472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = processor.process_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:25:21.752520Z","iopub.execute_input":"2025-07-16T11:25:21.752938Z","iopub.status.idle":"2025-07-16T11:31:08.265447Z","shell.execute_reply.started":"2025-07-16T11:25:21.752901Z","shell.execute_reply":"2025-07-16T11:31:08.264454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom IPython.core.display import display, HTML\n\nos.chdir('/kaggle/working')\n\n# üß† –û—Ç—Ä–∏–º—É—î–º–æ —ñ–º'—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –¥–∞—Ç–∞—Å–µ—Ç–æ–º\ndataset_folder = DatasetConfig.dataset_name  # –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, \"coco\"\nzip_filename = f\"{dataset_folder}.zip\"\nprint(f\"Creating archive: {zip_filename}\")\n\n# üß© –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–º—ñ–Ω–Ω—É —É shell-–∫–æ–º–∞–Ω–¥—ñ —á–µ—Ä–µ–∑ –ø–æ–¥–≤—ñ–π–Ω—ñ –¥—É–∂–∫–∏\n!zip -r -q \"$zip_filename\" \"$dataset_folder\"\n\nzip_path = f'/kaggle/working/{zip_filename}'\nif os.path.exists(zip_path):\n    file_size = os.path.getsize(zip_path) / (1024*1024)  # MB\n    print(f\"\\n‚úÖ Archive created successfully!\")\n    print(f\"üìÅ File: {zip_filename}\")\n    print(f\"üìä Size: {file_size:.1f} MB\")\n    print(f\"üìç Path: {zip_path}\")\n\n    print(f\"\\nüìã Archive contents:\")\n    !zipinfo \"$zip_filename\" | head -20\n\n    display(HTML(f\"\"\"\n    <div style=\"background-color: #e8f5e8; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n        <h3>üì• Download Ready</h3>\n        <a href=\"{zip_filename}\" download style=\"background-color: #4CAF50; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold;\">\n        üì• Download {zip_filename} ({file_size:.1f} MB)\n        </a>\n    </div>\n    \"\"\"))\nelse:\n    print(\"‚ùå Error: Archive not created!\")\n    print(\"Checking working directory contents:\")\n    !ls -la /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:35:17.713877Z","iopub.execute_input":"2025-07-16T11:35:17.714236Z","iopub.status.idle":"2025-07-16T11:35:46.713454Z","shell.execute_reply.started":"2025-07-16T11:35:17.714210Z","shell.execute_reply":"2025-07-16T11:35:46.712271Z"}},"outputs":[],"execution_count":null}]}