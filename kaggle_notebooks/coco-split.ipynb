{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 1462296,
     "sourceType": "datasetVersion",
     "datasetId": 857191
    },
    {
     "sourceId": 12422288,
     "sourceType": "datasetVersion",
     "datasetId": 7835092
    }
   ],
   "dockerImageVersionId": 31089,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import os\nimport json\nimport shutil\nimport random\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional, Set\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict, Counter\nimport warnings\n\n# Import required libraries\ntry:\n    from pycocotools.coco import COCO\n    from PIL import Image\n    from tqdm import tqdm\nexcept ImportError as e:\n    print(f\"Missing required library: {e}\")\n    print(\"Please install with: pip install pycocotools tqdm pillow\")\n    exit(1)\n\n# Suppress COCO API warnings\nwarnings.filterwarnings('ignore')",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T11:53:55.434315Z",
     "iopub.execute_input": "2025-07-16T11:53:55.434638Z",
     "iopub.status.idle": "2025-07-16T11:53:55.442062Z",
     "shell.execute_reply.started": "2025-07-16T11:53:55.434604Z",
     "shell.execute_reply": "2025-07-16T11:53:55.440826Z"
    }
   },
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass DatasetConfig:\n    \"\"\"Configuration for dataset creation\"\"\"\n    \n    # Basic settings\n    random_seed: int = 42\n    dataset_name: str = \"coco_sama\"\n    \n    # COCO dataset path\n    coco_path: str = '/kaggle/input/coco-2017-dataset/coco2017'\n    \n    # Output path\n    output_path: str = '/kaggle/working'\n    \n    # Category mapping - this is exactly what you want\n    category_mapping: Dict[str, List[str]] = field(default_factory=lambda: {\n        'person': ['person'],\n        'pet': ['cat', 'dog'],\n        'car': ['bus', 'truck', 'car']\n    })\n    \n    # Dataset split configuration\n    dataset_sizes: Dict[str, Dict[str, int]] = field(default_factory=lambda: {\n        'train': {'person': 6500, 'pet': 6500, 'car': 6500, 'negative': 3000},\n        'val': {'person': 2000, 'pet': 2000, 'car': 2000, 'negative': 1000}\n    })\n    \n    # Merge train2017 and val2017 before splitting\n    merge_splits: bool = True\n    \n    def __post_init__(self):\n        self.full_output_path = os.path.join(self.output_path, self.dataset_name)\n        self.all_target_categories = [cat for cats in self.category_mapping.values() for cat in cats]\n        \n        # Create reverse mapping for category ID conversion\n        self.category_to_group = {}\n        for group, categories in self.category_mapping.items():\n            for category in categories:\n                self.category_to_group[category] = group\n        \n        print(f\"Dataset config initialized: {self.dataset_name}\")\n        print(f\"Target categories: {self.all_target_categories}\")\n        print(f\"Category mapping: {self.category_mapping}\")\n        print(f\"Output path: {self.full_output_path}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T12:04:54.828969Z",
     "iopub.execute_input": "2025-07-16T12:04:54.830275Z",
     "iopub.status.idle": "2025-07-16T12:04:54.841032Z",
     "shell.execute_reply.started": "2025-07-16T12:04:54.830217Z",
     "shell.execute_reply": "2025-07-16T12:04:54.840012Z"
    }
   },
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": "class COCOProcessor:\n    \"\"\"Main class for processing COCO dataset\"\"\"\n    \n    def __init__(self, config: DatasetConfig):\n        self.config = config\n        self.coco_train = None\n        self.coco_val = None\n        self.merged_data = None\n        self.category_stats = {}\n        self.new_categories = []\n        self.old_to_new_cat_id = {}\n        \n        # Setup random seed\n        random.seed(config.random_seed)\n        print(f\"Random seed set to: {config.random_seed}\")\n    \n    def setup_directories(self):\n        \"\"\"Create necessary output directories\"\"\"\n        print(\"Setting up output directories...\")\n        \n        # Create main output directory\n        Path(self.config.full_output_path).mkdir(exist_ok=True, parents=True)\n        \n        # Create split directories\n        for split in ['train', 'val']:\n            Path(self.config.full_output_path, split).mkdir(exist_ok=True)\n        \n        # Create annotations directory\n        Path(self.config.full_output_path, 'annotations').mkdir(exist_ok=True)\n        \n        print(\"Directories created successfully\")\n    \n    def load_coco_data(self):\n        \"\"\"Load COCO train and val datasets\"\"\"\n        print(\"Loading COCO datasets...\")\n        \n        try:\n            # Load train dataset\n            # train_ann_file = os.path.join(self.config.coco_path, 'annotations', 'instances_train2017.json')\n            train_ann_file = os.path.join(\"/kaggle/input/merged-coco/merged_train.json\")\n\n            self.coco_train = COCO(train_ann_file)\n            print(f\"Loaded COCO train: {len(self.coco_train.getImgIds())} images\")\n            \n            # Load val dataset\n            # val_ann_file = os.path.join(self.config.coco_path, 'annotations', 'instances_val2017.json')\n            val_ann_file = os.path.join(\"/kaggle/input/merged-coco/merged_val.json\")\n\n            self.coco_val = COCO(val_ann_file)\n            print(f\"Loaded COCO val: {len(self.coco_val.getImgIds())} images\")\n            \n        except Exception as e:\n            printr(f\"Error loading COCO data: {e}\")\n            raise\n    \n    def merge_datasets(self):\n        \"\"\"Merge train and val datasets into one unified dataset\"\"\"\n        print(\"Merging train and val datasets...\")\n        \n        try:\n            # Get all images from both datasets\n            train_images = self.coco_train.dataset['images']\n            val_images = self.coco_val.dataset['images']\n            \n            # Get all annotations from both datasets\n            train_annotations = self.coco_train.dataset['annotations']\n            val_annotations = self.coco_val.dataset['annotations']\n            \n            # Adjust IDs to avoid conflicts\n            max_img_id = max([img['id'] for img in train_images])\n            max_ann_id = max([ann['id'] for ann in train_annotations])\n            \n            # Update val image IDs\n            img_id_mapping = {}\n            for img in val_images:\n                old_id = img['id']\n                new_id = max_img_id + old_id\n                img['id'] = new_id\n                img_id_mapping[old_id] = new_id\n            \n            # Update val annotation IDs and image references\n            for ann in val_annotations:\n                ann['id'] = max_ann_id + ann['id']\n                ann['image_id'] = img_id_mapping[ann['image_id']]\n            \n            # Merge data\n            merged_images = train_images + val_images\n            merged_annotations = train_annotations + val_annotations\n            merged_categories = self.coco_train.dataset['categories']  # Same categories in both\n            \n            # Create merged dataset structure\n            self.merged_data = {\n                'images': merged_images,\n                'annotations': merged_annotations,\n                'categories': merged_categories\n            }\n            \n            print(f\"Merged dataset: {len(merged_images)} images, {len(merged_annotations)} annotations\")\n            \n        except Exception as e:\n            print(f\"Error merging datasets: {e}\")\n            raise\n    \n    def setup_category_mapping(self):\n        \"\"\"Setup category mapping for remapping COCO categories to new categories\"\"\"\n        print(\"Setting up category mapping...\")\n        \n        try:\n            # Create temporary COCO object for merged data\n            temp_coco = COCO()\n            temp_coco.dataset = self.merged_data\n            temp_coco.createIndex()\n            \n            # Create new category structure\n            self.new_categories = []\n            self.old_to_new_cat_id = {}\n            \n            new_cat_id = 1\n            for group, categories in self.config.category_mapping.items():\n                # Create new category for this group\n                new_category = {\n                    'id': new_cat_id,\n                    'name': group,\n                    'supercategory': group\n                }\n                self.new_categories.append(new_category)\n                \n                # Map old category IDs to new category ID\n                for category in categories:\n                    old_cat_ids = temp_coco.getCatIds(catNms=[category])\n                    for old_cat_id in old_cat_ids:\n                        self.old_to_new_cat_id[old_cat_id] = new_cat_id\n                        print(f\"Mapping {category} (ID: {old_cat_id}) -> {group} (ID: {new_cat_id})\")\n                \n                new_cat_id += 1\n            \n            print(f\"Created {len(self.new_categories)} new categories\")\n            \n        except Exception as e:\n            print(f\"Error setting up category mapping: {e}\")\n            raise\n    \n    def analyze_category_distribution(self):\n        \"\"\"Analyze distribution of target categories in the merged dataset\"\"\"\n        print(\"Analyzing category distribution...\")\n        \n        try:\n            # Create temporary COCO object for merged data\n            temp_coco = COCO()\n            temp_coco.dataset = self.merged_data\n            temp_coco.createIndex()\n            \n            # Get target category IDs\n            target_cat_ids = temp_coco.getCatIds(catNms=self.config.all_target_categories)\n            \n            # Count images per category\n            category_counts = {}\n            total_target_images = set()\n            \n            for group, categories in self.config.category_mapping.items():\n                group_images = set()\n                group_counts = {}\n                \n                for category in categories:\n                    cat_ids = temp_coco.getCatIds(catNms=[category])\n                    if cat_ids:\n                        img_ids = temp_coco.getImgIds(catIds=cat_ids)\n                        group_counts[category] = len(img_ids)\n                        group_images.update(img_ids)\n                        total_target_images.update(img_ids)\n                    else:\n                        group_counts[category] = 0\n                        print(f\"Category '{category}' not found in dataset\")\n                \n                category_counts[group] = {\n                    'categories': group_counts,\n                    'total_images': len(group_images),\n                    'total_annotations': len(temp_coco.getAnnIds(imgIds=list(group_images), catIds=temp_coco.getCatIds(catNms=categories)))\n                }\n            \n            # Count negative images (images without any target categories)\n            all_img_ids = temp_coco.getImgIds()\n            negative_images = set(all_img_ids) - total_target_images\n            category_counts['negative'] = {\n                'categories': {'negative': len(negative_images)},\n                'total_images': len(negative_images),\n                'total_annotations': 0\n            }\n            \n            self.category_stats = category_counts\n            \n            # Log statistics\n            print(\"=== CATEGORY DISTRIBUTION ANALYSIS ===\")\n            for group, stats in category_counts.items():\n                print(f\"{group.upper()}:\")\n                if group != 'negative':\n                    for cat, count in stats['categories'].items():\n                        print(f\"  {cat}: {count:,} images\")\n                print(f\"  Total {group} images: {stats['total_images']:,}\")\n                print(f\"  Total {group} annotations: {stats['total_annotations']:,}\")\n                print(\"\")\n            \n            total_images = len(all_img_ids)\n            total_target = len(total_target_images)\n            print(f\"SUMMARY:\")\n            print(f\"  Total images in dataset: {total_images:,}\")\n            print(f\"  Images with target categories: {total_target:,}\")\n            print(f\"  Negative images: {len(negative_images):,}\")\n            print(f\"  Target coverage: {(total_target/total_images)*100:.1f}%\")\n            \n        except Exception as e:\n            print(f\"Error analyzing category distribution: {e}\")\n            raise\n    \n    def sample_images_for_category(self, temp_coco, categories: List[str], target_count: int, already_sampled: Set[int]) -> List[int]:\n        \"\"\"Sample images for a specific category group\"\"\"\n        group_img_ids = set()\n        \n        # Collect all images that contain any of the categories\n        for category in categories:\n            cat_ids = temp_coco.getCatIds(catNms=[category])\n            if cat_ids:\n                img_ids = temp_coco.getImgIds(catIds=cat_ids)\n                group_img_ids.update(img_ids)\n        \n        # Remove already sampled images\n        available_ids = [img_id for img_id in group_img_ids if img_id not in already_sampled]\n        sample_count = min(target_count, len(available_ids))\n        \n        if sample_count > 0:\n            sampled = random.sample(available_ids, sample_count)\n            print(f\"  {' + '.join(categories)}: {sample_count:,} / {len(available_ids):,} images\")\n            return sampled\n        \n        return []\n    \n    def sample_images_by_category(self, target_counts: Dict[str, int]) -> Dict[str, List[int]]:\n        \"\"\"Sample images from each category according to target counts\"\"\"\n        print(f\"Sampling images with target counts: {target_counts}\")\n        \n        try:\n            # Create temporary COCO object for merged data\n            temp_coco = COCO()\n            temp_coco.dataset = self.merged_data\n            temp_coco.createIndex()\n            \n            sampled_images = {}\n            all_sampled = set()\n            \n            # Sample from each category group\n            for group, target_count in target_counts.items():\n                if group == 'negative':\n                    continue  # Handle negative separately\n                \n                categories = self.config.category_mapping[group]\n                sampled = self.sample_images_for_category(temp_coco, categories, target_count, all_sampled)\n                \n                if sampled:\n                    sampled_images[group] = sampled\n                    all_sampled.update(sampled)\n            \n            # Sample negative images\n            if 'negative' in target_counts:\n                target_cat_ids = temp_coco.getCatIds(catNms=self.config.all_target_categories)\n                all_img_ids = temp_coco.getImgIds()\n                \n                negative_candidates = []\n                for img_id in all_img_ids:\n                    if img_id in all_sampled:\n                        continue\n                    \n                    ann_ids = temp_coco.getAnnIds(imgIds=[img_id], catIds=target_cat_ids)\n                    if len(ann_ids) == 0:\n                        negative_candidates.append(img_id)\n                \n                neg_count = target_counts['negative']\n                sample_count = min(neg_count, len(negative_candidates))\n                \n                if sample_count > 0:\n                    negative_sampled = random.sample(negative_candidates, sample_count)\n                    sampled_images['negative'] = negative_sampled\n                    print(f\"  negative: {sample_count:,} / {len(negative_candidates):,} images\")\n            \n            return sampled_images\n            \n        except Exception as e:\n            print(f\"Error sampling images: {e}\")\n            raise\n    \n    def create_split_dataset(self, split: str, sampled_images: Dict[str, List[int]]) -> Tuple[int, int]:\n        \"\"\"Create dataset split with sampled images and remapped categories\"\"\"\n        print(f\"Creating {split} dataset...\")\n        \n        try:\n            # Create temporary COCO object for merged data\n            temp_coco = COCO()\n            temp_coco.dataset = self.merged_data\n            temp_coco.createIndex()\n            \n            # Collect all sampled image IDs\n            all_img_ids = []\n            for group, img_ids in sampled_images.items():\n                all_img_ids.extend(img_ids)\n            \n            unique_img_ids = list(set(all_img_ids))\n            print(f\"Processing {len(unique_img_ids)} unique images for {split}\")\n            \n            # Load images\n            images = temp_coco.loadImgs(unique_img_ids)\n            \n            # Process annotations with category remapping\n            annotations = []\n            negative_imgs = set(sampled_images.get('negative', []))\n            \n            for img_id in tqdm(unique_img_ids, desc=f\"Processing {split} annotations\"):\n                if img_id not in negative_imgs:\n                    # Get all annotations for this image\n                    ann_ids = temp_coco.getAnnIds(imgIds=[img_id])\n                    img_annotations = temp_coco.loadAnns(ann_ids)\n                    \n                    # Filter and remap annotations\n                    for ann in img_annotations:\n                        old_cat_id = ann['category_id']\n                        if old_cat_id in self.old_to_new_cat_id:\n                            # Remap category ID\n                            ann['category_id'] = self.old_to_new_cat_id[old_cat_id]\n                            annotations.append(ann)\n            \n            # Copy image files\n            print(f\"Copying {len(images)} images to {split} directory...\")\n            \n            for img in tqdm(images, desc=f\"Copying {split} images\"):\n                # Determine source directory (train2017 or val2017)\n                src_train = os.path.join(self.config.coco_path, 'train2017', img['file_name'])\n                src_val = os.path.join(self.config.coco_path, 'val2017', img['file_name'])\n                \n                if os.path.exists(src_train):\n                    src_path = src_train\n                elif os.path.exists(src_val):\n                    src_path = src_val\n                else:\n                    print(f\"Image not found: {img['file_name']}\")\n                    continue\n                \n                dst_path = os.path.join(self.config.full_output_path, split, img['file_name'])\n                shutil.copy2(src_path, dst_path)\n            \n            # Save annotation file with remapped categories\n            annotation_data = {\n                'images': images,\n                'annotations': annotations,\n                'categories': self.new_categories\n            }\n            \n            ann_file = os.path.join(self.config.full_output_path, 'annotations', f'instances_{split}.json')\n            with open(ann_file, 'w') as f:\n                json.dump(annotation_data, f)\n            \n            print(f\"‚úÖ {split} dataset created: {len(images):,} images, {len(annotations):,} annotations\")\n            print(f\"Categories remapped: {len(self.new_categories)} new categories\")\n            \n            return len(images), len(annotations)\n            \n        except Exception as e:\n            print(f\"Error creating {split} dataset: {e}\")\n            raise\n    \n    def process_dataset(self):\n        \"\"\"Main processing pipeline\"\"\"\n        print(\"Starting dataset processing pipeline...\")\n        \n        try:\n            # Step 1: Setup\n            self.setup_directories()\n            \n            # Step 2: Load COCO data\n            self.load_coco_data()\n            \n            # Step 3: Merge datasets if configured\n            if self.config.merge_splits:\n                self.merge_datasets()\n            \n            # Step 4: Setup category mapping\n            self.setup_category_mapping()\n            \n            # Step 5: Analyze category distribution\n            self.analyze_category_distribution()\n            \n            # Step 6: Process each split\n            results = {}\n            \n            for split in ['train', 'val']:\n                if split not in self.config.dataset_sizes:\n                    print(f\"Split '{split}' not found in dataset_sizes config\")\n                    continue\n                \n                print(f\"\\n{'='*50}\")\n                print(f\"Processing {split.upper()} split\")\n                print(f\"{'='*50}\")\n                \n                # Sample images for this split\n                sampled_images = self.sample_images_by_category(self.config.dataset_sizes[split])\n                \n                # Create dataset\n                img_count, ann_count = self.create_split_dataset(split, sampled_images)\n                results[split] = {'images': img_count, 'annotations': ann_count}\n            \n            # Final summary\n            print(f\"\\n{'='*50}\")\n            print(\"FINAL DATASET SUMMARY\")\n            print(f\"{'='*50}\")\n            \n            total_images = 0\n            total_annotations = 0\n            \n            for split, stats in results.items():\n                print(f\"{split.capitalize()}: {stats['images']:,} images, {stats['annotations']:,} annotations\")\n                total_images += stats['images']\n                total_annotations += stats['annotations']\n            \n            print(f\"Total: {total_images:,} images, {total_annotations:,} annotations\")\n            print(f\"New categories: {[cat['name'] for cat in self.new_categories]}\")\n            print(f\"‚úÖ Dataset created successfully at: {self.config.full_output_path}\")\n            \n            return results\n            \n        except Exception as e:\n            print(f\"Error in processing pipeline: {e}\")\n            raise",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T12:05:01.636358Z",
     "iopub.execute_input": "2025-07-16T12:05:01.636660Z",
     "iopub.status.idle": "2025-07-16T12:05:01.680247Z",
     "shell.execute_reply.started": "2025-07-16T12:05:01.636640Z",
     "shell.execute_reply": "2025-07-16T12:05:01.679455Z"
    }
   },
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "source": "config = DatasetConfig()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T12:05:07.863028Z",
     "iopub.execute_input": "2025-07-16T12:05:07.863387Z",
     "iopub.status.idle": "2025-07-16T12:05:07.868403Z",
     "shell.execute_reply.started": "2025-07-16T12:05:07.863365Z",
     "shell.execute_reply": "2025-07-16T12:05:07.867264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Dataset config initialized: coco_sama\nTarget categories: ['person', 'cat', 'dog', 'bus', 'truck', 'car']\nCategory mapping: {'person': ['person'], 'pet': ['cat', 'dog'], 'car': ['bus', 'truck', 'car']}\nOutput path: /kaggle/working/coco_sama\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "source": "processor = COCOProcessor(config)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T12:05:09.814428Z",
     "iopub.execute_input": "2025-07-16T12:05:09.814744Z",
     "iopub.status.idle": "2025-07-16T12:05:12.691600Z",
     "shell.execute_reply.started": "2025-07-16T12:05:09.814720Z",
     "shell.execute_reply": "2025-07-16T12:05:12.690382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Random seed set to: 42\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "source": "results = processor.process_dataset()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T12:05:36.271649Z",
     "iopub.execute_input": "2025-07-16T12:05:36.272074Z",
     "iopub.status.idle": "2025-07-16T12:09:10.176936Z",
     "shell.execute_reply.started": "2025-07-16T12:05:36.272037Z",
     "shell.execute_reply": "2025-07-16T12:09:10.175639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Starting dataset processing pipeline...\nSetting up output directories...\nDirectories created successfully\nLoading COCO datasets...\nloading annotations into memory...\nDone (t=30.65s)\ncreating index...\nindex created!\nLoaded COCO train: 118287 images\nloading annotations into memory...\nDone (t=0.85s)\ncreating index...\nindex created!\nLoaded COCO val: 5000 images\nMerging train and val datasets...\nMerged dataset: 123287 images, 1115464 annotations\nSetting up category mapping...\ncreating index...\nindex created!\nMapping person (ID: 1) -> person (ID: 1)\nMapping cat (ID: 17) -> pet (ID: 2)\nMapping dog (ID: 18) -> pet (ID: 2)\nMapping bus (ID: 6) -> car (ID: 3)\nMapping truck (ID: 8) -> car (ID: 3)\nMapping car (ID: 3) -> car (ID: 3)\nCreated 3 new categories\nAnalyzing category distribution...\ncreating index...\nindex created!\n=== CATEGORY DISTRIBUTION ANALYSIS ===\nPERSON:\n  person: 68,659 images\n  Total person images: 68,659\n  Total person annotations: 373,972\n\nPET:\n  cat: 4,345 images\n  dog: 4,700 images\n  Total pet images: 8,839\n  Total pet annotations: 11,252\n\nCAR:\n  bus: 4,192 images\n  truck: 6,906 images\n  car: 13,314 images\n  Total car images: 17,733\n  Total car annotations: 67,553\n\nNEGATIVE:\n  Total negative images: 44,030\n  Total negative annotations: 0\n\nSUMMARY:\n  Total images in dataset: 123,287\n  Images with target categories: 79,257\n  Negative images: 44,030\n  Target coverage: 64.3%\n\n==================================================\nProcessing TRAIN split\n==================================================\nSampling images with target counts: {'person': 6500, 'pet': 6500, 'car': 6500, 'negative': 3000}\ncreating index...\nindex created!\n  person: 6,500 / 68,659 images\n  cat + dog: 6,500 / 8,534 images\n  bus + truck + car: 6,500 / 15,934 images\n  negative: 3,000 / 44,030 images\nCreating train dataset...\ncreating index...\nindex created!\nProcessing 22500 unique images for train\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Processing train annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22500/22500 [00:00<00:00, 115485.05it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Copying 22500 images to train directory...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Copying train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22500/22500 [02:03<00:00, 182.82it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "‚úÖ train dataset created: 22,500 images, 112,098 annotations\nCategories remapped: 3 new categories\n\n==================================================\nProcessing VAL split\n==================================================\nSampling images with target counts: {'person': 2000, 'pet': 2000, 'car': 2000, 'negative': 1000}\ncreating index...\nindex created!\n  person: 2,000 / 68,659 images\n  cat + dog: 1,915 / 1,915 images\n  bus + truck + car: 2,000 / 17,234 images\n  negative: 1,000 / 48,089 images\nCreating val dataset...\ncreating index...\nindex created!\nProcessing 6915 unique images for val\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Processing val annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6915/6915 [00:00<00:00, 107159.63it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Copying 6915 images to val directory...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Copying val images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6915/6915 [00:36<00:00, 190.89it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "‚úÖ val dataset created: 6,915 images, 34,264 annotations\nCategories remapped: 3 new categories\n\n==================================================\nFINAL DATASET SUMMARY\n==================================================\nTrain: 22,500 images, 112,098 annotations\nVal: 6,915 images, 34,264 annotations\nTotal: 29,415 images, 146,362 annotations\nNew categories: ['person', 'pet', 'car']\n‚úÖ Dataset created successfully at: /kaggle/working/coco_sama\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "source": "import os\nfrom IPython.core.display import display, HTML\n\nos.chdir('/kaggle/working')\n\n# üß† –û—Ç—Ä–∏–º—É—î–º–æ —ñ–º'—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –¥–∞—Ç–∞—Å–µ—Ç–æ–º\ndataset_folder = DatasetConfig.dataset_name  # –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, \"coco\"\nzip_filename = f\"{dataset_folder}.zip\"\nprint(f\"Creating archive: {zip_filename}\")\n\n# üß© –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–º—ñ–Ω–Ω—É —É shell-–∫–æ–º–∞–Ω–¥—ñ —á–µ—Ä–µ–∑ –ø–æ–¥–≤—ñ–π–Ω—ñ –¥—É–∂–∫–∏\n!zip -r -q \"$zip_filename\" \"$dataset_folder\"\n\nzip_path = f'/kaggle/working/{zip_filename}'\nif os.path.exists(zip_path):\n    file_size = os.path.getsize(zip_path) / (1024*1024)  # MB\n    print(f\"\\n‚úÖ Archive created successfully!\")\n    print(f\"üìÅ File: {zip_filename}\")\n    print(f\"üìä Size: {file_size:.1f} MB\")\n    print(f\"üìç Path: {zip_path}\")\n\n    print(f\"\\nüìã Archive contents:\")\n    !zipinfo \"$zip_filename\" | head -20\n\n    display(HTML(f\"\"\"\n    <div style=\"background-color: #e8f5e8; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n        <h3>üì• Download Ready</h3>\n        <a href=\"{zip_filename}\" download style=\"background-color: #4CAF50; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold;\">\n        üì• Download {zip_filename} ({file_size:.1f} MB)\n        </a>\n    </div>\n    \"\"\"))\nelse:\n    print(\"‚ùå Error: Archive not created!\")\n    print(\"Checking working directory contents:\")\n    !ls -la /kaggle/working/\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-16T12:09:10.178802Z",
     "iopub.execute_input": "2025-07-16T12:09:10.179552Z",
     "iopub.status.idle": "2025-07-16T12:13:00.623922Z",
     "shell.execute_reply.started": "2025-07-16T12:09:10.179527Z",
     "shell.execute_reply": "2025-07-16T12:13:00.622509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Creating archive: coco_sama.zip\n\n‚úÖ Archive created successfully!\nüìÅ File: coco_sama.zip\nüìä Size: 4571.6 MB\nüìç Path: /kaggle/working/coco_sama.zip\n\nüìã Archive contents:\nArchive:  coco_sama.zip\nZip file size: 4793667254 bytes, number of entries: 29421\ndrwxr-xr-x  3.0 unx        0 bx stor 25-Jul-16 12:05 coco_sama/\ndrwxr-xr-x  3.0 unx        0 bx stor 25-Jul-16 12:09 coco_sama/annotations/\n-rw-r--r--  3.0 unx 21151900 tx defN 25-Jul-16 12:09 coco_sama/annotations/instances_val.json\n-rw-r--r--  3.0 unx 69501892 tx defN 25-Jul-16 12:08 coco_sama/annotations/instances_train.json\ndrwxr-xr-x  3.0 unx        0 bx stor 25-Jul-16 12:08 coco_sama/train/\n-rw-r--r--  3.0 unx   111650 bx defN 25-Apr-17 20:11 coco_sama/train/000000415990.jpg\n-rw-r--r--  3.0 unx   115050 bx defN 25-Apr-17 20:07 coco_sama/train/000000237284.jpg\n-rw-r--r--  3.0 unx   240080 bx defN 25-Apr-17 20:05 coco_sama/train/000000092096.jpg\n-rw-r--r--  3.0 unx   153119 bx defN 25-Apr-17 20:09 coco_sama/train/000000443397.jpg\n-rw-r--r--  3.0 unx   181255 bx defN 25-Apr-17 20:07 coco_sama/train/000000273088.jpg\n-rw-r--r--  3.0 unx   354317 bx defN 25-Apr-17 20:09 coco_sama/train/000000392827.jpg\n-rw-r--r--  3.0 unx   254826 bx defN 25-Apr-17 20:10 coco_sama/train/000000488014.jpg\n-rw-r--r--  3.0 unx   269857 bx defN 25-Apr-17 20:04 coco_sama/train/000000032284.jpg\n-rw-r--r--  3.0 unx   308713 bx defN 25-Apr-17 20:10 coco_sama/train/000000521998.jpg\n-rw-r--r--  3.0 unx   161069 bx defN 25-Apr-17 20:06 coco_sama/train/000000217937.jpg\n-rw-r--r--  3.0 unx   282201 bx defN 25-Apr-17 20:04 coco_sama/train/000000052952.jpg\n-rw-r--r--  3.0 unx   119999 bx defN 25-Apr-17 20:05 coco_sama/train/000000095227.jpg\n-rw-r--r--  3.0 unx   246398 bx defN 25-Apr-17 20:04 coco_sama/train/000000039446.jpg\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div style=\"background-color: #e8f5e8; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n        <h3>üì• Download Ready</h3>\n        <a href=\"coco_sama.zip\" download style=\"background-color: #4CAF50; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold;\">\n        üì• Download coco_sama.zip (4571.6 MB)\n        </a>\n    </div>\n    "
     },
     "metadata": {}
    }
   ],
   "execution_count": 90
  }
 ]
}
