{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CY3stEJbWomz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ofpcd3SZh2t"
      },
      "source": [
        "# plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def safe_filename(filename: str) -> str:\n",
        "    \"\"\"Clean filename from special characters.\"\"\"\n",
        "    return re.sub(r'[^a-zA-Z0-9\\-.]', '', filename)"
      ],
      "metadata": {
        "id": "DQZEhh3IwBKb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DATA LOADING AND PROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def load_csv_files(csv_files: List[str]) -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"Load multiple CSV files into a dictionary of DataFrames.\"\"\"\n",
        "    data = {}\n",
        "    for f in csv_files:\n",
        "        try:\n",
        "            name = os.path.splitext(os.path.basename(f))[0]\n",
        "            df = pd.read_csv(f)\n",
        "            data[name] = df\n",
        "            print(f\"✓ Loaded {name}: {len(df)} rows, {len(df.columns)} columns\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading {f}: {e}\")\n",
        "    return data\n",
        "\n",
        "def extract_numeric_metrics(data: Dict[str, pd.DataFrame]) -> List[str]:\n",
        "    \"\"\"Extract all numeric columns that are metrics (excluding epoch and lr).\"\"\"\n",
        "    numeric_cols = {\n",
        "        col\n",
        "        for df in data.values()\n",
        "        for col in df.select_dtypes(include=['float32', 'float64']).columns\n",
        "    }\n",
        "    metrics = [\n",
        "        m for m in numeric_cols\n",
        "        if 'epoch' not in m.lower() and 'lr' not in m.lower()\n",
        "    ]\n",
        "    return sorted(metrics)\n",
        "\n",
        "def get_final_epoch_metrics(data: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
        "    \"\"\"Extract metrics from the final epoch for comparison table.\"\"\"\n",
        "    final_metrics = []\n",
        "\n",
        "    for name, df in data.items():\n",
        "        if 'epoch' in df.columns:\n",
        "            final_row = df.iloc[-1].copy()  # Last row (final epoch)\n",
        "            final_row['model'] = name\n",
        "            final_row['epoch'] = int(final_row['epoch'])\n",
        "            final_metrics.append(final_row)\n",
        "        else:\n",
        "            print(f\"Warning: No 'epoch' column found in {name}\")\n",
        "\n",
        "    if not final_metrics:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Create comparison table\n",
        "    comparison_df = pd.DataFrame(final_metrics)\n",
        "\n",
        "    # Reorder columns: model, epoch, then metrics\n",
        "    cols = ['model', 'epoch'] + [col for col in comparison_df.columns\n",
        "                                if col not in ['model', 'epoch']]\n",
        "    comparison_df = comparison_df[cols]\n",
        "\n",
        "    return comparison_df"
      ],
      "metadata": {
        "id": "91P2L4FMwF6b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def plot_metrics(\n",
        "    data: Dict[str, pd.DataFrame],\n",
        "    output_dir: str = '/content/metrics_analysis',\n",
        "    fmt: str = 'jpg',\n",
        "    dpi: int = 80,\n",
        "    figsize: tuple = (8, 4),\n",
        "    quality: int = 50\n",
        ") -> None:\n",
        "    \"\"\"Create plots for all metrics across models.\"\"\"\n",
        "    plots_dir = os.path.join(output_dir, 'plots')\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    metrics = extract_numeric_metrics(data)\n",
        "\n",
        "    if not metrics:\n",
        "        print(\"No metrics found to plot.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Creating plots for metrics: {', '.join(metrics)}\")\n",
        "\n",
        "    for metric in metrics:\n",
        "        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
        "\n",
        "        for name, df in data.items():\n",
        "            if metric in df.columns and 'epoch' in df.columns:\n",
        "                ax.plot(df['epoch'], df[metric], label=name, marker='o', markersize=3)\n",
        "\n",
        "        ax.set_title(f'{metric} Over Training Epochs')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel(metric)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save plot\n",
        "        fname = safe_filename(metric) + ('.jpg' if fmt.lower() in ('jpg','jpeg') else '.png')\n",
        "        save_path = os.path.join(plots_dir, fname)\n",
        "\n",
        "        if fmt.lower() in ('jpg', 'jpeg'):\n",
        "            fig.savefig(\n",
        "                save_path,\n",
        "                format='jpeg',\n",
        "                dpi=dpi,\n",
        "                pil_kwargs={'quality': quality, 'optimize': True}\n",
        "            )\n",
        "        else:\n",
        "            fig.savefig(\n",
        "                save_path,\n",
        "                format='png',\n",
        "                dpi=dpi,\n",
        "                compress_level=9,\n",
        "                optimize=True\n",
        "            )\n",
        "\n",
        "        plt.close(fig)\n",
        "\n",
        "    print(f\"✓ Created {len(metrics)} plots in {plots_dir} (format: {fmt}, dpi: {dpi})\")\n"
      ],
      "metadata": {
        "id": "UVFANhfdwIPs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TABLE GENERATION AND SAVING\n",
        "# ============================================================================\n",
        "\n",
        "def save_metrics_table(\n",
        "    data: Dict[str, pd.DataFrame],\n",
        "    output_dir: str = '/content/metrics_analysis',\n",
        "    save_formats: List[str] = ['csv', 'xlsx']\n",
        ") -> None:\n",
        "    \"\"\"Save final epoch metrics in table format for comparison.\"\"\"\n",
        "    tables_dir = os.path.join(output_dir, 'tables')\n",
        "    os.makedirs(tables_dir, exist_ok=True)\n",
        "\n",
        "    # Get final metrics\n",
        "    final_metrics = get_final_epoch_metrics(data)\n",
        "\n",
        "    if final_metrics.empty:\n",
        "        print(\"No final metrics to save.\")\n",
        "        return\n",
        "\n",
        "    # Add validation note\n",
        "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "    base_filename = f'final_validation_metrics_{timestamp}'\n",
        "\n",
        "    # Save in requested formats\n",
        "    for fmt in save_formats:\n",
        "        if fmt.lower() == 'csv':\n",
        "            filepath = os.path.join(tables_dir, f'{base_filename}.csv')\n",
        "            final_metrics.to_csv(filepath, index=False)\n",
        "            print(f\"✓ Saved validation metrics table: {filepath}\")\n",
        "\n",
        "        elif fmt.lower() in ['xlsx', 'excel']:\n",
        "            filepath = os.path.join(tables_dir, f'{base_filename}.xlsx')\n",
        "            with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
        "                final_metrics.to_excel(writer, sheet_name='Final_Validation_Metrics', index=False)\n",
        "\n",
        "                # Add a note sheet\n",
        "                note_df = pd.DataFrame({\n",
        "                    'Note': ['These are VALIDATION metrics from the final epoch of training',\n",
        "                             'NOT test set results',\n",
        "                             f'Generated on: {pd.Timestamp.now()}',\n",
        "                             f'Models compared: {\", \".join(data.keys())}']\n",
        "                })\n",
        "                note_df.to_excel(writer, sheet_name='README', index=False)\n",
        "            print(f\"✓ Saved validation metrics table: {filepath}\")\n",
        "\n",
        "    return final_metrics\n",
        "\n",
        "def display_metrics_table(data: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
        "    \"\"\"Display final metrics in a formatted table.\"\"\"\n",
        "    final_metrics = get_final_epoch_metrics(data)\n",
        "\n",
        "    if final_metrics.empty:\n",
        "        print(\"No metrics to display.\")\n",
        "        return final_metrics\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL VALIDATION METRICS COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Note: These are VALIDATION metrics from the final training epoch\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Format for display\n",
        "    display_df = final_metrics.copy()\n",
        "\n",
        "    # Round numeric columns to 3 decimal places\n",
        "    numeric_cols = display_df.select_dtypes(include=['float32', 'float64']).columns\n",
        "    display_df[numeric_cols] = display_df[numeric_cols].round(3)\n",
        "\n",
        "    print(display_df.to_string(index=False))\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    return final_metrics\n"
      ],
      "metadata": {
        "id": "hPYYs-YWwIzb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def run_full_analysis(\n",
        "    csv_files: List[str],\n",
        "    plot_config: Dict = None,\n",
        "    save_table: bool = True,\n",
        "    table_formats: List[str] = ['csv', 'xlsx']\n",
        ") -> Tuple[Dict[str, pd.DataFrame], pd.DataFrame]:\n",
        "    \"\"\"Run complete analysis: load data, create plots, and save comparison table.\"\"\"\n",
        "\n",
        "    # Default plot configuration\n",
        "    if plot_config is None:\n",
        "        plot_config = {\n",
        "            'output_dir': '/content/metrics_analysis',\n",
        "            'fmt': 'jpg',\n",
        "            'dpi': 75,\n",
        "            'figsize': (20, 10),\n",
        "            'quality': 75\n",
        "        }\n",
        "\n",
        "    print(\"Starting metrics analysis...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. Load data\n",
        "    print(\"\\n1. Loading CSV files...\")\n",
        "    data = load_csv_files(csv_files)\n",
        "\n",
        "    if not data:\n",
        "        print(\"No data loaded. Exiting.\")\n",
        "        return {}, pd.DataFrame()\n",
        "\n",
        "    # 2. Create plots\n",
        "    print(\"\\n2. Creating metric plots...\")\n",
        "    plot_metrics(data, **plot_config)\n",
        "\n",
        "    # 3. Display and save final metrics table\n",
        "    print(\"\\n3. Processing final validation metrics...\")\n",
        "    final_metrics = display_metrics_table(data)\n",
        "\n",
        "    if save_table and not final_metrics.empty:\n",
        "        print(\"\\n4. Saving metrics table...\")\n",
        "        save_metrics_table(data, output_dir=plot_config['output_dir'], save_formats=table_formats)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Analysis complete!\")\n",
        "\n",
        "    return data, final_metrics\n"
      ],
      "metadata": {
        "id": "pwQUDLEewL46"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Example usage of the metrics analysis tool.\"\"\"\n",
        "\n",
        "# Method 1: Upload files in Colab and run full analysis\n",
        "print(\"Upload your CSV files:\")\n",
        "uploaded = files.upload()\n",
        "csv_files = list(uploaded.keys())\n",
        "\n",
        "# Run complete analysis with custom settings\n",
        "data, final_metrics = run_full_analysis(\n",
        "    csv_files,\n",
        "    plot_config={\n",
        "        'output_dir': '/content/metrics_analysis',\n",
        "        'fmt': 'jpg',\n",
        "        'dpi': 75,\n",
        "        'figsize': (20, 10),\n",
        "        'quality': 75\n",
        "    },\n",
        "    save_table=True,\n",
        "    table_formats=['csv', 'xlsx']\n",
        ")\n",
        "\n",
        "# Method 2: Step by step analysis\n",
        "# data = load_csv_files(csv_files)\n",
        "# plot_metrics(data, fmt='png', dpi=100, figsize=(12, 8))\n",
        "# final_metrics = display_metrics_table(data)\n",
        "# save_metrics_table(data, save_formats=['csv'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DhkB1E9twQtM",
        "outputId": "a8be0d13-31da-42cd-e60a-09373e8677a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your CSV files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b372ace8-026a-4657-ab37-d2f9854b71ec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b372ace8-026a-4657-ab37-d2f9854b71ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yolo8n_pt_512_coco_balanced_full.csv to yolo8n_pt_512_coco_balanced_full.csv\n",
            "Saving yolo8n_pt_512_coco_full_training.csv to yolo8n_pt_512_coco_full_training.csv\n",
            "Saving yolo8n_pt_512_coco_sama_balanced_full.csv to yolo8n_pt_512_coco_sama_balanced_full.csv\n",
            "Saving yolo8n_pt_512_coco_sama_full_training.csv to yolo8n_pt_512_coco_sama_full_training.csv\n",
            "Saving yolo8n_pt_512_coco_sama_skiped_crowd.csv to yolo8n_pt_512_coco_sama_skiped_crowd.csv\n",
            "Saving yolo8n_pt_512_coco_sama_skiped_crowd_3_85.csv to yolo8n_pt_512_coco_sama_skiped_crowd_3_85.csv\n",
            "Saving yolo8n_pt_512_coco_skiped_crowd.csv to yolo8n_pt_512_coco_skiped_crowd.csv\n",
            "Saving yolo8n_pt_512_coco_skiped_crowd_2.5_95.csv to yolo8n_pt_512_coco_skiped_crowd_2.5_95.csv\n",
            "Saving yolo8n_pt_512_coco_skiped_crowd_3_85.csv to yolo8n_pt_512_coco_skiped_crowd_3_85.csv\n",
            "Starting metrics analysis...\n",
            "==================================================\n",
            "\n",
            "1. Loading CSV files...\n",
            "✓ Loaded yolo8n_pt_512_coco_balanced_full: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_full_training: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_sama_balanced_full: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_sama_full_training: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_sama_skiped_crowd: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_sama_skiped_crowd_3_85: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_skiped_crowd: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_skiped_crowd_2.5_95: 50 rows, 15 columns\n",
            "✓ Loaded yolo8n_pt_512_coco_skiped_crowd_3_85: 50 rows, 15 columns\n",
            "\n",
            "2. Creating metric plots...\n",
            "Creating plots for metrics: metrics/mAP50(B), metrics/mAP50-95(B), metrics/precision(B), metrics/recall(B), time, train/box_loss, train/cls_loss, train/dfl_loss, val/box_loss, val/cls_loss, val/dfl_loss\n",
            "✓ Created 11 plots in /content/metrics_analysis/plots (format: jpg, dpi: 75)\n",
            "\n",
            "3. Processing final validation metrics...\n",
            "\n",
            "================================================================================\n",
            "FINAL VALIDATION METRICS COMPARISON\n",
            "================================================================================\n",
            "Note: These are VALIDATION metrics from the final training epoch\n",
            "--------------------------------------------------------------------------------\n",
            "                                    model  epoch    time  train/box_loss  train/cls_loss  train/dfl_loss  metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss  lr/pg0  lr/pg1  lr/pg2\n",
            "         yolo8n_pt_512_coco_balanced_full     50 3466.00           0.889           0.662           1.054                 0.773              0.605             0.672                0.459         1.094         0.889         1.162     0.0     0.0     0.0\n",
            "         yolo8n_pt_512_coco_full_training     50 9244.72           1.058           0.772           1.079                 0.774              0.632             0.690                0.480         1.123         0.856         1.096     0.0     0.0     0.0\n",
            "    yolo8n_pt_512_coco_sama_balanced_full     50 3632.62           0.932           0.746           1.074                 0.765              0.573             0.653                0.449         1.118         0.956         1.149     0.0     0.0     0.0\n",
            "    yolo8n_pt_512_coco_sama_full_training     50 9528.90           1.098           0.856           1.091                 0.759              0.609             0.668                0.467         1.137         0.909         1.084     0.0     0.0     0.0\n",
            "     yolo8n_pt_512_coco_sama_skiped_crowd     50 8576.53           0.986           0.805           1.080                 0.774              0.633             0.691                0.498         1.044         0.885         1.077     0.0     0.0     0.0\n",
            "yolo8n_pt_512_coco_sama_skiped_crowd_3_85     50 8440.54           0.895           0.759           1.074                 0.812              0.704             0.772                0.575         0.963         0.855         1.088     0.0     0.0     0.0\n",
            "          yolo8n_pt_512_coco_skiped_crowd     50 8480.33           0.985           0.725           1.063                 0.799              0.648             0.708                0.499         1.052         0.814         1.081     0.0     0.0     0.0\n",
            "   yolo8n_pt_512_coco_skiped_crowd_2.5_95     50 8741.64           0.907           0.690           1.065                 0.825              0.726             0.792                0.580         0.981         0.796         1.090     0.0     0.0     0.0\n",
            "     yolo8n_pt_512_coco_skiped_crowd_3_85     50 8361.59           0.899           0.682           1.065                 0.833              0.731             0.800                0.590         0.973         0.788         1.091     0.0     0.0     0.0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "4. Saving metrics table...\n",
            "✓ Saved validation metrics table: /content/metrics_analysis/tables/final_validation_metrics_20250802_122614.csv\n",
            "✓ Saved validation metrics table: /content/metrics_analysis/tables/final_validation_metrics_20250802_122614.xlsx\n",
            "\n",
            "==================================================\n",
            "Analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt3HPW-uZ3H9",
        "outputId": "dedfeb1b-a729-4abd-a576-a4f94710a8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/metrics_analysis/ (stored 0%)\n",
            "  adding: content/metrics_analysis/plots/ (stored 0%)\n",
            "  adding: content/metrics_analysis/plots/valdflloss.jpg (deflated 24%)\n",
            "  adding: content/metrics_analysis/plots/metricsprecisionB.jpg (deflated 22%)\n",
            "  adding: content/metrics_analysis/plots/trainboxloss.jpg (deflated 23%)\n",
            "  adding: content/metrics_analysis/plots/trainclsloss.jpg (deflated 25%)\n",
            "  adding: content/metrics_analysis/plots/time.jpg (deflated 26%)\n",
            "  adding: content/metrics_analysis/plots/metricsmAP50B.jpg (deflated 22%)\n",
            "  adding: content/metrics_analysis/plots/metricsmAP50-95B.jpg (deflated 23%)\n",
            "  adding: content/metrics_analysis/plots/valboxloss.jpg (deflated 23%)\n",
            "  adding: content/metrics_analysis/plots/traindflloss.jpg (deflated 24%)\n",
            "  adding: content/metrics_analysis/plots/metricsrecallB.jpg (deflated 21%)\n",
            "  adding: content/metrics_analysis/plots/valclsloss.jpg (deflated 24%)\n",
            "  adding: content/metrics_analysis/tables/ (stored 0%)\n",
            "  adding: content/metrics_analysis/tables/final_validation_metrics_20250802_122614.csv (deflated 64%)\n",
            "  adding: content/metrics_analysis/tables/final_validation_metrics_20250802_122614.xlsx (deflated 10%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/metrics_analysis.zip /content/metrics_analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/metrics_plots"
      ],
      "metadata": {
        "id": "hxv9bqn6PKQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_usage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0YtvWH62yKKT",
        "outputId": "e8385195-848c-464e-c8c5-7ee6e9513e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your CSV files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5c1d666-2095-43f6-9f09-84fe7bb7a1f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5c1d666-2095-43f6-9f09-84fe7bb7a1f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving coco_16.csv to coco_16.csv\n",
            "Saving coco_64.csv to coco_64.csv\n",
            "Saving coco_128.csv to coco_128.csv\n",
            "Saving sama_16.csv to sama_16.csv\n",
            "Saving sama_64.csv to sama_64.csv\n",
            "Starting metrics analysis...\n",
            "==================================================\n",
            "\n",
            "1. Loading CSV files...\n",
            "✓ Loaded coco_16: 50 rows, 15 columns\n",
            "✓ Loaded coco_64: 50 rows, 15 columns\n",
            "✓ Loaded coco_128: 50 rows, 15 columns\n",
            "✓ Loaded sama_16: 50 rows, 15 columns\n",
            "✓ Loaded sama_64: 50 rows, 15 columns\n",
            "\n",
            "2. Creating metric plots...\n",
            "Creating plots for metrics: metrics/mAP50(B), metrics/mAP50-95(B), metrics/precision(B), metrics/recall(B), time, train/box_loss, train/cls_loss, train/dfl_loss, val/box_loss, val/cls_loss, val/dfl_loss\n",
            "✓ Created 11 plots in /content/metrics_analysis/plots (format: jpg, dpi: 75)\n",
            "\n",
            "3. Processing final validation metrics...\n",
            "\n",
            "================================================================================\n",
            "FINAL VALIDATION METRICS COMPARISON\n",
            "================================================================================\n",
            "Note: These are VALIDATION metrics from the final training epoch\n",
            "--------------------------------------------------------------------------------\n",
            "   model  epoch     time  train/box_loss  train/cls_loss  train/dfl_loss  metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss  lr/pg0  lr/pg1  lr/pg2\n",
            " coco_16     50 11757.20           1.088           0.841           1.104                 0.803              0.643             0.728                0.521         1.100         0.831         1.084     0.0     0.0     0.0\n",
            " coco_64     50  9481.85           1.074           0.808           1.092                 0.810              0.648             0.735                0.529         1.094         0.812         1.078     0.0     0.0     0.0\n",
            "coco_128     50  9311.77           1.055           0.774           1.081                 0.830              0.655             0.744                0.538         1.084         0.790         1.070     0.0     0.0     0.0\n",
            " sama_16     50 11884.90           1.098           0.892           1.104                 0.795              0.619             0.708                0.508         1.119         0.889         1.074     0.0     0.0     0.0\n",
            " sama_64     50  9735.21           1.096           0.855           1.091                 0.797              0.626             0.719                0.517         1.121         0.872         1.069     0.0     0.0     0.0\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "4. Saving metrics table...\n",
            "✓ Saved validation metrics table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071418.csv\n",
            "✓ Saved validation metrics table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071418.xlsx\n",
            "✓ Saved metrics table image: /content/metrics_analysis/tables/final_validation_metrics_20250714_071418.png\n",
            "✓ Saved metrics table image: /content/metrics_analysis/tables/final_validation_metrics_20250714_071418.jpg\n",
            "\n",
            "5. Creating styled table versions...\n",
            "✓ Saved professional styled table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071421_professional.png\n",
            "✓ Saved professional styled table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071421_professional.jpg\n",
            "✓ Saved modern styled table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071421_modern.png\n",
            "✓ Saved modern styled table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071421_modern.jpg\n",
            "✓ Saved colorful styled table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071421_colorful.png\n",
            "✓ Saved colorful styled table: /content/metrics_analysis/tables/final_validation_metrics_20250714_071421_colorful.jpg\n",
            "\n",
            "==================================================\n",
            "Analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewgaWConZj_F"
      },
      "source": [
        "# videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXoP6KlnZnGf",
        "outputId": "39ae3f65-9bf7-46b6-daa0-0867bd7e05d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.171)\n",
            "Requirement already satisfied: sahi in /usr/local/lib/python3.11/dist-packages (0.11.31)\n",
            "Requirement already satisfied: lap in /usr/local/lib/python3.11/dist-packages (0.5.12)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi) (8.2.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from sahi) (0.7.0)\n",
            "Requirement already satisfied: pybboxes==0.1.6 in /usr/local/lib/python3.11/dist-packages (from sahi) (0.1.6)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi) (2.1.1)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.11/dist-packages (from sahi) (3.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->sahi) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics sahi lap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqQLjt6mZmst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478d91fe-51cd-46f5-bf9a-6081bd87cdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o--uAfMqZcPo",
        "outputId": "e974f4bd-0797-439f-ea25-814493ce13b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: /content/models\n",
            "Created directory: /content/videos\n",
            "Created directory: /content/results\n",
            "\n",
            "Папки створено. Тепер ви можете вручну закинути:\n",
            "1. Моделі .pt в /content/models\n",
            "2. Відео в /content/videos\n",
            "3. Результати будуть в /content/results\n"
          ]
        }
      ],
      "source": [
        "# Створення основних директорій\n",
        "base_dirs = [\n",
        "    '/content/models',  # Директорія для моделей .pt\n",
        "    '/content/videos',  # Директорія для вихідних відео\n",
        "    '/content/results'  # Директорія для результатів\n",
        "]\n",
        "\n",
        "for dir_path in base_dirs:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    print(f\"Created directory: {dir_path}\")\n",
        "\n",
        "print(\"\\nПапки створено. Тепер ви можете вручну закинути:\")\n",
        "print(\"1. Моделі .pt в /content/models\")\n",
        "print(\"2. Відео в /content/videos\")\n",
        "print(\"3. Результати будуть в /content/results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBWMU8g2ePr2",
        "outputId": "d715db1d-0b9f-47c8-b68a-b10b77dece51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking yolo8n_pt_512_coco_balanced_full: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_balanced_full: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:27<00:00, 59.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_balanced_full: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:43<00:00, 61.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_balanced_full: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:26<00:00, 17.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_balanced_full: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:10<00:00, 42.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_balanced_full: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:26<00:00, 55.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:27<00:00, 60.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:43<00:00, 61.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:25<00:00, 17.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:08<00:00, 43.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:27<00:00, 55.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_full_training: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_full_training: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:27<00:00, 59.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_full_training: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:42<00:00, 62.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_full_training: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:25<00:00, 17.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_full_training: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:09<00:00, 42.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_full_training: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:26<00:00, 56.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:27<00:00, 60.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:43<00:00, 61.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:25<00:00, 17.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:08<00:00, 43.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:27<00:00, 55.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_full_training: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_full_training: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:26<00:00, 60.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_full_training: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:44<00:00, 61.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_full_training: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:25<00:00, 17.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_full_training: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:09<00:00, 42.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_full_training: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:27<00:00, 55.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd_3_85: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd_3_85: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:26<00:00, 61.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd_3_85: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:42<00:00, 63.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd_3_85: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:25<00:00, 17.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd_3_85: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:10<00:00, 42.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_skiped_crowd_3_85: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:26<00:00, 56.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd_3_85: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:35<00:00, 17.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd_3_85: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:26<00:00, 61.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd_3_85: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:43<00:00, 62.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd_3_85: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:24<00:00, 18.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd_3_85: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:09<00:00, 42.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_skiped_crowd_3_85: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:27<00:00, 54.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_balanced_full: 535.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 535.mp4: 100%|██████████| 619/619 [00:34<00:00, 18.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 535.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_balanced_full: dogs.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ dogs.mp4: 100%|██████████| 1641/1641 [00:28<00:00, 58.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: dogs.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_balanced_full: Shibuya.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ Shibuya.mp4: 100%|██████████| 2690/2690 [00:43<00:00, 61.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: Shibuya.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_balanced_full: 508.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ 508.mp4: 100%|██████████| 452/452 [00:25<00:00, 17.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: 508.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_balanced_full: ring_doorbell.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ ring_doorbell.mp4: 100%|█████████▉| 2953/2956 [01:08<00:00, 42.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: ring_doorbell.mp4\n",
            "Tracking yolo8n_pt_512_coco_sama_balanced_full: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  ▶ persons.mp4: 100%|██████████| 1501/1501 [00:26<00:00, 55.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Completed: persons.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "class VideoTrackingConfig:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Конфігурація гіперпараметрів для трекінгу об'єктів у відео\n",
        "        \"\"\"\n",
        "        # Параметри трекінгу/детекції\n",
        "        self.CONFIDENCE_THRESHOLD = 0.7\n",
        "        self.IOU_THRESHOLD = 0.6\n",
        "        self.MAX_DETECTIONS = 300\n",
        "        self.AGNOSTIC_NMS = False\n",
        "        self.SELECTED_CLASSES = None\n",
        "\n",
        "        # Візуалізація\n",
        "        self.DRAW_LABELS = True\n",
        "        self.DRAW_CONFIDENCE = True\n",
        "        self.BBOX_THICKNESS = 2\n",
        "        self.LABEL_FONT_SCALE = 0.7\n",
        "\n",
        "        # Відео вивід\n",
        "        self.OUTPUT_CODEC = 'mp4v'\n",
        "        self.RESIZE_OUTPUT = None  # (width, height)\n",
        "\n",
        "        # Трекінг\n",
        "        self.TRACKING = True  # Увімкнути трекінг\n",
        "        self.PERSIST_LABELS = True  # Покращене збереження ID треків на об'єктах\n",
        "\n",
        "\n",
        "def main_tracking(config=None):\n",
        "    \"\"\"\n",
        "    Основна функція для трекінгу об'єктів у відео\n",
        "    \"\"\"\n",
        "    import os\n",
        "    from ultralytics import YOLO\n",
        "    import cv2\n",
        "\n",
        "    if config is None:\n",
        "        config = VideoTrackingConfig()\n",
        "\n",
        "    MODELS_DIR = '/content/models'\n",
        "    VIDEOS_DIR = '/content/videos'\n",
        "    RESULTS_DIR = '/content/results'\n",
        "\n",
        "    model_files = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n",
        "    video_files = [f for f in os.listdir(VIDEOS_DIR) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_name = os.path.splitext(model_file)[0]\n",
        "        model_results_dir = os.path.join(RESULTS_DIR, model_name)\n",
        "        os.makedirs(model_results_dir, exist_ok=True)\n",
        "\n",
        "        model = YOLO(os.path.join(MODELS_DIR, model_file))\n",
        "\n",
        "        model.overrides.update({\n",
        "            'conf': config.CONFIDENCE_THRESHOLD,\n",
        "            'iou': config.IOU_THRESHOLD,\n",
        "            'max_det': config.MAX_DETECTIONS,\n",
        "            'agnostic_nms': config.AGNOSTIC_NMS,\n",
        "            'classes': config.SELECTED_CLASSES\n",
        "        })\n",
        "\n",
        "\n",
        "        for video_file in video_files:\n",
        "            input_path = os.path.join(VIDEOS_DIR, video_file)\n",
        "            output_path = os.path.join(model_results_dir, video_file)\n",
        "\n",
        "            print(f\"Tracking {model_name}: {video_file}\")\n",
        "\n",
        "            try:\n",
        "                cap = cv2.VideoCapture(input_path)\n",
        "                if not cap.isOpened():\n",
        "                    print(f\"Error: Cannot open video file {input_path}\")\n",
        "                    continue\n",
        "\n",
        "                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "                if config.RESIZE_OUTPUT:\n",
        "                    width, height = config.RESIZE_OUTPUT\n",
        "\n",
        "                fourcc = cv2.VideoWriter_fourcc(*config.OUTPUT_CODEC)\n",
        "                out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "                cap.release()\n",
        "\n",
        "\n",
        "                model.tracker = None\n",
        "\n",
        "                results = model.track(\n",
        "                    source=input_path,\n",
        "                    stream=True,\n",
        "                    persist=config.PERSIST_LABELS,\n",
        "                    conf=config.CONFIDENCE_THRESHOLD,\n",
        "                    iou=config.IOU_THRESHOLD,\n",
        "                    classes=config.SELECTED_CLASSES,\n",
        "                    verbose=False,\n",
        "                )\n",
        "\n",
        "                for result in tqdm(results, total=total_frames, desc=f\"  ▶ {video_file}\"):\n",
        "                    annotated_frame = result.plot(\n",
        "                        conf=config.DRAW_CONFIDENCE,\n",
        "                        labels=config.DRAW_LABELS,\n",
        "                        font_size=config.LABEL_FONT_SCALE,\n",
        "                        line_width=config.BBOX_THICKNESS\n",
        "                    )\n",
        "\n",
        "                    if config.RESIZE_OUTPUT:\n",
        "                        annotated_frame = cv2.resize(annotated_frame, config.RESIZE_OUTPUT)\n",
        "\n",
        "                    out.write(annotated_frame)\n",
        "\n",
        "                out.release()\n",
        "                print(f\"  ✅ Completed: {video_file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error tracking {video_file}: {str(e)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Виклик з кастомною конфігурацією\n",
        "custom_config = VideoTrackingConfig()\n",
        "main_tracking(custom_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onewa5P_bNLs",
        "outputId": "45d9c3a2-adc4-459e-d31e-33daac78971a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/508.mp4 (deflated 4%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/508.mp4 (deflated 5%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd_3_85/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/508.mp4 (deflated 4%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_skiped_crowd/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/508.mp4 (deflated 5%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_balanced_full/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/508.mp4 (deflated 5%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_full_training/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/508.mp4 (deflated 4%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_sama_balanced_full/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/508.mp4 (deflated 5%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_full_training/persons.mp4 (deflated 3%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/ (stored 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/535.mp4 (deflated 0%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/dogs.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/Shibuya.mp4 (deflated 2%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/508.mp4 (deflated 4%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/ring_doorbell.mp4 (deflated 7%)\n",
            "  adding: content/results/yolo8n_pt_512_coco_skiped_crowd_3_85/persons.mp4 (deflated 3%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/results.zip /content/results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOEBTv2tNqWC",
        "outputId": "525d8f9e-582a-4bad-8e58-aaecd59bd256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/results.zip /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "9pucfXzDNV7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}